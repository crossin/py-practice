# Python操作Spark

### 【解决思路】

我们的目的只是简单介绍一下如何Python操作Spark，因此并没有布置特别困难的任务。WordCount程序在大数据处理领域，就如“Hello world”程序一样经典，如果你实在不会的话，可以在Spark官网找到相应的示例（当然也可以参考我们提供的样例代码）。

本次实验，之前学过的函数式编程思想将发挥很大作用，你会更加清楚地体会到函数式编程的优雅与高效。

有关交互式命令行方式执行，和提交`.py`文件执行的最主要区别在于。命令行下，系统默认创建了Spark的上下文（`sc`变量），而你在`.py`文件里，需要自己创建。另外，你需要使用`pyspark`来启动Spark交互式命令行，使用`spark-submit`来提交你的代码，而不是直接使用Python运行，毕竟我们是要去操作Spark的，不是么？

另外，你或许会觉得用Spark很慢，比你直接用Python处理要慢多了，这很正常。不过设想一下，如果你要统计的文件有几百个G大呢？你那简单的程序还能hold住么？