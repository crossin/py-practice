# 中文分词

### 【解决思路】

中文分词是一个非常困难的任务，完全靠自己实现显然不现实。并且一个优秀的分词器，还需要大量的数据进行训练，这也是我们没有条件去实现的。

Python下比较好的分词工具是"[结巴](https://pypi.python.org/pypi/jieba/0.38)"，你可以很容易地使用`pip`安装它，然后使用它提供的接口，对中文句子进行分词。

在安装好后，你需要阅读相关文档，调用可以实现你需求的接口，完成任务。

需要注意的是，第一次使用时，可能需要训练模型，会占用一定时间，请耐心等待。